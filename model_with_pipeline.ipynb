{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as learn\n",
    "import tensorflow as tf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, model_name, file_name):\n",
    "        self.model_name = model_name\n",
    "        self.file_name = file_name\n",
    "    \n",
    "    def create_dataset(self):\n",
    "        return pd.read_csv(self.file_name)\n",
    "    \n",
    "    def get_columns_name(self):\n",
    "        return list(self.create_dataset().columns)\n",
    "    \n",
    "    def create_features_labels(self, index_of_labels=-1):\n",
    "        df = self.create_dataset()\n",
    "        labels = df.iloc[:,index_of_labels]\n",
    "        features = df[df.columns.difference([labels.name])]\n",
    "        return features, labels\n",
    "    \n",
    "    def create_train_test_set(self, ratio=0.2):\n",
    "        from sklearn.cross_validation import train_test_split\n",
    "        X, y = self.create_features_labels()\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=ratio)\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "a  = Model(\"ania\", \"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = a.create_dataset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = a.create_train_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct some pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "\n",
    "pipe_lr = Pipeline([('scl', StandardScaler()),\n",
    "                    ('pca', PCA(n_components=2)),\n",
    "                    ('clf', LogisticRegression(random_state=42))])\n",
    "\n",
    "pipe_svm = Pipeline([('scl', StandardScaler()),\n",
    "                     ('pca', PCA(n_components=2)),\n",
    "                     ('clf', svm.SVC(random_state=42))])\n",
    "\n",
    "pipe_dt = Pipeline([('scl', StandardScaler()),\n",
    "                    ('pca', PCA(n_components=2)),\n",
    "                    ('clf', tree.DecisionTreeClassifier(random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression pipeline test accuracy: 0.932\n",
      "Support Vector Machine pipeline test accuracy: 0.932\n",
      "Decision Tree pipeline test accuracy: 0.917\n",
      "Classifier with best accuracy: Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipelines = [pipe_lr, pipe_svm, pipe_dt]\n",
    "\n",
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "pipe_dict = {0: 'Logistic Regression', 1: 'Support Vector Machine', 2: 'Decision Tree'}\n",
    "\n",
    "# Fit the pipelines\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(X_train, Y_train)\n",
    "\n",
    "# Compare accuracies\n",
    "for idx, val in enumerate(pipelines):\n",
    "    print('%s pipeline test accuracy: %.3f' % (pipe_dict[idx], val.score(X_test, Y_test)))\n",
    "\n",
    "# Identify the most accurate model on test data\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_pipe = ''\n",
    "for idx, val in enumerate(pipelines):\n",
    "    if val.score(X_test,Y_test) > best_acc:\n",
    "        best_acc = val.score(X_test, Y_test)\n",
    "        best_pipe = val\n",
    "        best_clf = idx\n",
    "print('Classifier with best accuracy: %s' % pipe_dict[best_clf])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
